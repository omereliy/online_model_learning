# Information Gain Algorithm - Blocksworld Domain
# Uses greedy selection strategy (always picks max expected gain)
#
# CONFIGURATION MODES:
# 1. Exploratory (current): Quick validation with aggressive convergence (max_iterations: 200)
# 2. Full Experiment: Change max_iterations to 1000, remove/comment convergence overrides
#    to use conservative defaults (50, 0.001, 0.98, 50)

experiment:
  name: "information_gain_blocksworld_greedy"
  algorithm: "information_gain"
  seed: 42  # Change for different trials: 43, 44, 45, etc.
  environment_type: "pddl"

domain_problem:
  domain: "benchmarks/olam-compatible/blocksworld/domain.pddl"
  problem: "benchmarks/olam-compatible/blocksworld/p01.pddl"

# Algorithm-specific parameters
algorithm_params:
  information_gain:
    selection_strategy: "greedy"  # Options: "greedy", "epsilon_greedy", "boltzmann"
    max_iterations: 200            # Use 1000+ for full experiments

    # Convergence parameters (optional - defaults are conservative)
    # Current settings: AGGRESSIVE for quick exploratory experiments
    # For full experiments: REMOVE these lines to use conservative defaults
    model_stability_window: 10      # Default: 50 (no model changes for N iterations)
    info_gain_epsilon: 0.01          # Default: 0.001 (very low threshold)
    success_rate_threshold: 0.95     # Default: 0.98 (98% success rate)
    success_rate_window: 20          # Default: 50 (calculate over N recent actions)

    # Note: Convergence requires ALL 3 criteria to be met simultaneously

# Metrics collection
metrics:
  interval: 1  # Record every action
  window_size: 50

# Stopping criteria
stopping_criteria:
  max_iterations: 200                # Match algorithm_params max_iterations
  max_runtime_seconds: 600           # Use 3600+ for full experiments
  convergence_check_interval: 20     # Use 99999 to disable for full experiments

# Output configuration
output:
  directory: "results/"
  formats: ["csv", "json"]
  save_learned_model: true
